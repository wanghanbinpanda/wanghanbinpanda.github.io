---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a first-year Master‚Äôs student at National Engineering Research Center for Software Engineering, Peking University. Previously, I had the fortune to collaborate with researchers from [NEUIR](https://neuir.github.io/), [THUNLP](https://nlp.csai.tsinghua.edu.cn/), [ModelBest(Èù¢Â£ÅÊô∫ËÉΩ)](https://modelbest.cn/) and [Shanghai AI Lab](https://www.shlab.org.cn/). My research interests include Code Intelligence and LLM Reasoning.

# üìñ Educations

- *2024.09 - 2027.06*, National Engineering Research Center for Software Engineering, Peking University, Beijing, China.
- *2020.09 - 2024.06*, Software College, Northeastern University, Shenyang, China.

# üíº Internships

- *2024.07 - 2024.09*, Shanghai AI Laboratory, Beijing, China.
- *2023.10 - 2024.07*, TsinghuaNLP & ModelBest Inc (Èù¢Â£ÅÊô∫ËÉΩ) , Beijing, China.
- *2022.08 - 2024.07*, NEUIR Lab , Shenyang, China.
- *2023.03 - 2023.06*, The Knowledge Computing Lab, Peking University, Beijing, China.

# üìù Preprints

\* indicates equal contribution.

- **Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement** [[**Paper**](https://www.arxiv.org/abs/2408.05006)] 

  Weiqing Yang\*, **Hanbin Wang\***, Zhenghao Liu, Xinze Li, Yukun Yan, Shuo Wang, Yu Gu, Minghe Yu, Zhiyuan Liu, Ge Yu

# üìù Publications

\* indicates equal contribution.

- **(TOIS) Building A Coding Assistant via the Retrieval-Augmented Language Model**

  Xinze Li\*, **Hanbin Wang**\*, Zhenghao Liu, Shi Yu, Shuo Wang, Yukun Yan, Yukai Fu, Yu Gu, Ge Yu

- **(ICML 2024 Workshop on AI4Math) Advancing LLM Reasoning Generalists with Preference Trees** [[**Paper**](https://arxiv.org/abs/2404.02078)]

  Lifan Yuan\*, Ganqu Cui\*, **Hanbin Wang**\*, Ning Ding, Xingyao Wang, Jia Deng, Boji Shan, Huimin Chen, Ruobing Xie, Yankai Lin, Zhenghao Liu, Bowen Zhou, Hao Peng, Zhiyuan Liu, Maosong Sun.
  
- **(ACL 2024) INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing** [[**Paper**](https://arxiv.org/abs/2311.09868)] 

  **Hanbin Wang**, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan Liu, Ge Yu

